{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWiWPWKQXmAX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchaudio\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "from tqdm import tqdm\n",
        "from torchaudio.datasets import SPEECHCOMMANDS\n",
        "import os\n",
        "\n",
        "class SubsetSC(SPEECHCOMMANDS):\n",
        "    def __init__(self, subset: str = None):\n",
        "        super().__init__(\"./\", download=True)\n",
        "        def load_list(filename):\n",
        "            filepath = os.path.join(self._path, filename)\n",
        "            with open(filepath) as fileobj:\n",
        "                return [os.path.normpath(os.path.join(self._path, line.strip())) for line in fileobj]\n",
        "        if subset == \"validation\":\n",
        "            self._walker = load_list(\"validation_list.txt\")\n",
        "        elif subset == \"testing\":\n",
        "            self._walker = load_list(\"testing_list.txt\")\n",
        "        elif subset == \"training\":\n",
        "            excludes = load_list(\"validation_list.txt\") + load_list(\"testing_list.txt\")\n",
        "            excludes = set(excludes)\n",
        "            self._walker = [w for w in self._walker if w not in excludes]\n",
        "\n",
        "train_set = SubsetSC(\"training\")\n",
        "test_set = SubsetSC(\"testing\")\n",
        "\n",
        "waveform, sample_rate, label, speaker_id, utterance_number = train_set[0]\n",
        "\n",
        "new_sample_rate = 8000\n",
        "transform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=new_sample_rate)\n",
        "transformed = transform(waveform)\n",
        "\n",
        "def label_to_index(word):\n",
        "    return torch.tensor(labels.index(word))\n",
        "\n",
        "def index_to_label(index):\n",
        "    return labels[index]\n",
        "\n",
        "def pad_sequence(batch):\n",
        "    batch = [item.t() for item in batch]\n",
        "    batch = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=0.)\n",
        "    return batch.permute(0, 2, 1)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    tensors, targets = [], []\n",
        "    for waveform, _, label, *_ in batch:\n",
        "        tensors += [waveform]\n",
        "        targets += [label_to_index(label)]\n",
        "    tensors = pad_sequence(tensors)\n",
        "    targets = torch.stack(targets)\n",
        "    return tensors, targets\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    num_workers = 1\n",
        "    pin_memory = True\n",
        "else:\n",
        "    num_workers = 0\n",
        "    pin_memory = False\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory,\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory,\n",
        ")\n",
        "\n",
        "class M5(nn.Module):\n",
        "    def __init__(self, n_input=1, n_output=35, stride=16, n_channel=32):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n",
        "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
        "        self.pool1 = nn.MaxPool1d(4)\n",
        "        self.conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
        "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
        "        self.pool2 = nn.MaxPool1d(4)\n",
        "        self.conv3 = nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
        "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
        "        self.pool3 = nn.MaxPool1d(4)\n",
        "        self.conv4 = nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
        "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
        "        self.pool4 = nn.MaxPool1d(4)\n",
        "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(self.bn1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(self.bn2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(self.bn3(x))\n",
        "        x = self.pool3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(self.bn4(x))\n",
        "        x = self.pool4(x)\n",
        "        x = F.avg_pool1d(x, x.shape[-1])\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.fc1(x)\n",
        "        return F.log_softmax(x, dim=2)\n",
        "\n",
        "model = M5(n_input=transformed.shape[0], n_output=len(labels))\n",
        "model.to(device)\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "n = count_parameters(model)\n",
        "print(\"Number of parameters: %s\" % n)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
        "\n",
        "def train(model, epoch, log_interval):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        data = transform(data)\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output.squeeze(), target)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
        "        pbar.update(pbar_update)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "def number_of_correct(pred, target):\n",
        "    return pred.squeeze().eq(target).sum().item()\n",
        "\n",
        "def get_likely_index(tensor):\n",
        "    return tensor.argmax(dim=-1)\n",
        "\n",
        "def test(model, epoch):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        data = transform(data)\n",
        "        output = model(data)\n",
        "        pred = get_likely_index(output)\n",
        "        correct += number_of_correct(pred, target)\n",
        "        pbar.update(pbar_update)\n",
        "    print(f\"\\nTest Epoch: {epoch}\\tAccuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n\")\n",
        "\n",
        "log_interval = 20\n",
        "n_epoch = 2\n",
        "\n",
        "pbar_update = 1 / (len(train_loader) + len(test_loader))\n",
        "losses = []\n",
        "\n",
        "transform = transform.to(device)\n",
        "with tqdm(total=n_epoch) as pbar:\n",
        "    for epoch in range(1, n_epoch + 1):\n",
        "        train(model, epoch, log_interval)\n",
        "        test(model, epoch)\n",
        "        scheduler.step()\n",
        "\n",
        "def predict(tensor):\n",
        "    tensor = tensor.to(device)\n",
        "    tensor = transform(tensor)\n",
        "    tensor = model(tensor.unsqueeze(0))\n",
        "    tensor = get_likely_index(tensor)\n",
        "    tensor = index_to_label(tensor.squeeze())\n",
        "    return tensor\n",
        "\n",
        "waveform, sample_rate, utterance, *_ = train_set[-1]\n",
        "ipd.Audio(waveform.numpy(), rate=sample_rate)\n",
        "print(f\"Expected: {utterance}. Predicted: {predict(waveform)}.\")\n",
        "\n",
        "for i, (waveform, sample_rate, utterance, *_) in enumerate(test_set):\n",
        "    output = predict(waveform)\n",
        "    if output != utterance:\n",
        "        ipd.Audio(waveform.numpy(), rate=sample_rate)\n",
        "        print(f\"Data point #{i}. Expected: {utterance}. Predicted: {output}.\")\n",
        "        break\n",
        "else:\n",
        "    print(\"All examples in this dataset were correctly classified!\")\n",
        "    print(\"In this case, let's just look at the last data point\")\n",
        "    ipd.Audio(waveform.numpy(), rate=sample_rate)\n",
        "    print(f\"Data point #{i}. Expected: {utterance}. Predicted: {output}.\")\n",
        "\n",
        "def record(seconds=1):\n",
        "    from google.colab import output as colab_output\n",
        "    from base64 import b64decode\n",
        "    from io import BytesIO\n",
        "    from pydub import AudioSegment\n",
        "    RECORD = (\n",
        "        b\"const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\\n\"\n",
        "        b\"const b2text = blob => new Promise(resolve => {\\n\"\n",
        "        b\"  const reader = new FileReader()\\n\"\n",
        "        b\"  reader.onloadend = e => resolve(e.srcElement.result)\\n\"\n",
        "        b\"  reader.readAsDataURL(blob)\\n\"\n",
        "        b\"})\\n\"\n",
        "        b\"var record = time => new Promise(async resolve => {\\n\"\n",
        "        b\"  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\\n\"\n",
        "        b\"  recorder = new MediaRecorder(stream)\\n\"\n",
        "        b\"  chunks = []\\n\"\n",
        "        b\"  recorder.ondataavailable = e => chunks.push(e.data)\\n\"\n",
        "        b\"  recorder.start()\\n\"\n",
        "        b\"  await sleep(time)\\n\"\n",
        "        b\"  recorder.onstop = async ()=>{\\n\"\n",
        "        b\"    blob = new Blob(chunks)\\n\"\n",
        "        b\"    text = await b2text(blob)\\n\n"
      ]
    }
  ]
}